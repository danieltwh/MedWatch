{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5545cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectionmodel2 import Processor\n",
    "from augmentation import SingleFootageAugmenter\n",
    "from utils import get_subdirectories, get_filenames\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9920ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_mapping = {\n",
    "    0: '',\n",
    "    1: 'brightness',\n",
    "    2: 'img_noise',\n",
    "    3: 'img_blur',\n",
    "    4: 'cam_rotation',\n",
    "    5: 'brightness + img_noise',\n",
    "    6: 'brightness + img_blur',\n",
    "    7: 'brightness + cam_rotation',\n",
    "    8: 'img_noise + img_blur',\n",
    "    9: 'img_noise + cam_rotation',\n",
    "    10: 'img_blur + cam_rotation',\n",
    "    11: 'brightness + img_noise + img_blur',\n",
    "    12: 'brightness + img_noise + cam_rotation',\n",
    "    13: 'brightness + img_blur + cam_rotation',\n",
    "    14: 'img_noise + img_blur + cam_rotation',\n",
    "    15: 'brightness + img_noise + img_blur + cam_rotation'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96dd9b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_fall_detection(video_path, model, mode=0, frame_lag=False, frame_loss=False, \n",
    "                         connection_err=False, display_video=False, save_video=False, output_filename='output.avi'):\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open video\")\n",
    "        exit()\n",
    "\n",
    "    # Initialize the VideoWriter object only if save_video is True\n",
    "    if save_video:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(output_filename, fourcc, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "    # Create an instance of Processor\n",
    "    processor = Processor(model)\n",
    "    \n",
    "    test_mode = mode_mapping[mode]\n",
    "\n",
    "    while True:\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        single_frame_augmentor = SingleFootageAugmenter(frame)\n",
    "        \n",
    "        if 'brightness' in test_mode:\n",
    "            single_frame_augmentor.augment_brightness()\n",
    "        \n",
    "        if 'img_noise' in test_mode:\n",
    "            single_frame_augmentor.add_image_noise()\n",
    "        \n",
    "        if 'img_blur' in test_mode:\n",
    "            kernel_size = random.randrange(1, 16, 2)\n",
    "            single_frame_augmentor.adjust_image_blur(kernel_size=(kernel_size,kernel_size))\n",
    "        \n",
    "        if 'cam_rotation' in test_mode:\n",
    "            angle  = random.randrange(10, 360, 20)\n",
    "            updated_frames = single_frame_augmentor.adjust_camera_rotation(angle=angle)\n",
    "            \n",
    "        frame = single_frame_augmentor.output_augmented_frame()\n",
    "        # Process the frame using the Processor class\n",
    "        frame = processor.process(frame)\n",
    "\n",
    "        # Write the processed frame into the output video if save_video is True\n",
    "        if save_video:\n",
    "            out.write(frame)\n",
    "\n",
    "        # Display the processed frame if display_video is True\n",
    "        if display_video:\n",
    "            cv2.imshow(\"Fall Detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Release resources depending on the options chosen\n",
    "    cap.release()\n",
    "    if save_video:\n",
    "        out.release()\n",
    "    if display_video:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    # Return the statistics using the output_stats method from the Processor instance\n",
    "    return processor.output_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd09d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results(model,video_dir,fall_patterns_dir, mode=0, frame_lag=False, frame_loss=False, \n",
    "                         connection_err=False, display_video=False, save_video=False):\n",
    "    complete_test_results = []\n",
    "    for fall_pattern_path in fall_patterns_dir:\n",
    "        print(fall_pattern_path)\n",
    "        fall_pattern_full_path = Path(video_dir,fall_pattern_path)\n",
    "        cam_angles_paths = get_filenames(fall_pattern_full_path)\n",
    "        for cam_angles_path in cam_angles_paths:\n",
    "            print(cam_angles_path)\n",
    "            file_name = os.path.basename(cam_angles_path)\n",
    "            output_filename = f'Processed mode {mode} {file_name}.avi'\n",
    "            cam_angle_full_path = Path(fall_pattern_full_path,cam_angles_path)\n",
    "            output_filename = str(Path(video_dir,'Output',output_filename))\n",
    "            test_result = video_fall_detection(cam_angle_full_path,model, mode, frame_lag, frame_loss,\n",
    "                                               connection_err, display_video, save_video, output_filename)\n",
    "            test_result['Angle'] = cam_angles_path[:-4]\n",
    "            test_result['Fall Type'] = fall_pattern_path\n",
    "            complete_test_results.append(test_result)\n",
    "    df_results = pd.DataFrame(complete_test_results)\n",
    "    df_results['model'] = model\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b04c1b",
   "metadata": {},
   "source": [
    "# How to Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7f257f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = Path(os.getcwd(),'./Videos')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10f734",
   "metadata": {},
   "source": [
    "### In the List below enter the name of the subdirectories in Videos you would like to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3641f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fall_patterns_dir = ['wheelchair','baseline'] for e.g.\n",
    "\n",
    "fall_patterns_dir = ['wheelchair']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd290d7",
   "metadata": {},
   "source": [
    "### In the List below enter the name of the models you would like to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6778eb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['yolov8s-pose.pt']  for e.g.\n",
    "\n",
    "models = ['yolov8s-pose.pt']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be28cbb",
   "metadata": {},
   "source": [
    "### Tester Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d344a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modes = [1,2,3,4] look at mode_mapping to choose your mode and include them in the list\n",
    "# save_video = True Boolean to save video\n",
    "# display_video = False Boolean to save video\n",
    "\n",
    "modes = [1,2,3,4]\n",
    "save_video = True\n",
    "display_video = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "539452ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "yolov8s-pose.pt\n",
      "wheelchair\n",
      "wheelchair_calvin - 01.mp4\n",
      "Wheelchair_Daniel_1.mov\n",
      "2\n",
      "yolov8s-pose.pt\n",
      "wheelchair\n",
      "wheelchair_calvin - 01.mp4\n",
      "Wheelchair_Daniel_1.mov\n",
      "3\n",
      "yolov8s-pose.pt\n",
      "wheelchair\n",
      "wheelchair_calvin - 01.mp4\n",
      "Wheelchair_Daniel_1.mov\n",
      "4\n",
      "yolov8s-pose.pt\n",
      "wheelchair\n",
      "wheelchair_calvin - 01.mp4\n",
      "Wheelchair_Daniel_1.mov\n"
     ]
    }
   ],
   "source": [
    "complete_df_results = pd.DataFrame()\n",
    "backup_counter =  0\n",
    "for model in models:\n",
    "    for mode in modes:\n",
    "        print(mode)\n",
    "        print(model)\n",
    "        df_result = get_test_results(model,video_dir,fall_patterns_dir,mode=mode,save_video=save_video,display_video=display_video)\n",
    "        df_result.to_pickle(f'Data/df_result_{backup_counter}.pkl')\n",
    "        complete_df_results = pd.concat([complete_df_results,df_result]).reset_index(drop=True)\n",
    "        backup_counter+=1\n",
    "complete_df_results.to_pickle(f'Data/complete_results_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe084d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
